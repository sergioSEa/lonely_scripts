---
title: "Notebook LLNEXT: Analysis clusters/enterotypes and B.longum subspecies"
output: html_notebook
---


```{r,,warning=FALSE, message=FALSE}
library(tidyverse)
library(vegan)
library(ape)
library(cluster)
library(WeightedCluster)
library(viridis)
library(ggnewscale)
library(pals)
library(patchwork)

library(coda4microbiome)
library(tidymodels)
library(bonsai)
library(lightgbm)
library(pROC)

library(lmerTest)
```

# Part 1: Clustering

##1. Read MP4 table (normal)
```{r, warning=FALSE, message=FALSE}
df <-read.delim("~/Documents/PhD/LL_NEXT/Transmission/metadata/LLNEXT_metaphlan_4_CLEAN_10_07_2023.txt") %>% rownames_to_column("NG_ID")  %>% as_tibble()
#Filter to early timepoint
#There are 2 infants with more than one timepoint ; we arrange accoridng to exact_age_at_collection so that it will keep the earliest timepoint
read_tsv("~/Documents/PhD/LL_NEXT/Transmission/metadata/LLNEXT_metadata_03_01_2024.txt") %>% 
  select(NG_ID, NEXT_ID, Timepoint_categorical, exact_age_days_at_collection)   %>%   filter(Timepoint_categorical == "W2") %>% arrange(exact_age_days_at_collection) %>% dplyr::distinct(NEXT_ID, .keep_all=T ) -> InfoEarly 

df %>% filter(NG_ID %in% InfoEarly$NG_ID) -> Early

```
Alternatively, use the table obtained from MP4 using the database from D. Ennis et al. Nat. Communications 2024 (https://www.nature.com/articles/s41467-024-45209-y)
```{r, warning=FALSE, message=FALSE}
read_tsv("~/Documents/PhD/LL_NEXT/Transmission/metadata/LLNext_MP4_Blongum.txt", skip=1) -> df2
df2 %>% select(clade_name, one_of(df$NG_ID)) -> df2_2
df2_2$clade_name -> COLN  
df2_2 %>% select(-clade_name) %>% t() %>% as_tibble() %>% mutate(NG_ID = colnames(df2_2 %>% select(-clade_name) ), .before=1 ) -> df2_3
colnames(df2_3) = c("NG_ID", COLN)
#Need to remove contaminants
colnames(df2_3)[grepl("s__Sphingomonas_sp_FARSPH", colnames(df2_3) )] -> contaminants
df2_3 %>% select(-contaminants) -> df2_3


read_tsv("~/Documents/PhD/LL_NEXT/Transmission/metadata/LLNEXT_metadata_03_01_2024.txt") %>% 
  select(NG_ID, NEXT_ID, Timepoint_categorical, exact_age_days_at_collection)   %>% arrange(exact_age_days_at_collection) %>% dplyr::distinct(NEXT_ID, Timepoint_categorical, .keep_all=T ) -> InfoAll
df2_3 %>% filter(NG_ID %in% InfoAll$NG_ID) -> df2_3

colnames(df2_3) %>% sapply(function(x){str_replace_all(x, "\\|", ".") } ) -> colnames(df2_3)

#If we want to do the nexr steps using this database, add this line
df2_3  %>% filter(NG_ID %in% InfoEarly$NG_ID) -> Early


```

##2. Data preparation

Preparing for some cleaning up. Get functions ready

```{r, warning=FALSE, message=FALSE}
AST_transform = function(data){
  asin(sqrt(data/100))
}
Filter_names = function(DF, Do_Genus = T){
  if (Do_Genus == T){
    DF=DF[,c(1, grep('g__',colnames(DF)) )]
    Genus_name = colnames(DF)[sapply(strsplit(colnames(DF),"\\."),"length")==6]
    DF %>% select(c("NG_ID", Genus_name)) -> DF
    sapply(Genus_name, function(x){  str_split(x,"\\.")[[1]] -> y ; y[length(y)]   }  ) -> N_names
    colnames(DF) = c("NG_ID", N_names)
  } else {
    DF=DF[,c(1, grep('t__',colnames(DF)) )]
    colnames(DF)=gsub('.*s__','',colnames(DF))
  }
  return(DF)
}
Filter_XAbundance_in_YPrevalence = function(Early, Min_abundance=0.1, PercentageSamples=10){
  Prevalence = Early %>% select(-NG_ID) %>% apply(2, function(x){ sum(x>0)/length(x) } ) ; Prevalence = tibble(Taxa = names(Prevalence), Prev = Prevalence )
  Early %>% select(-NG_ID)  %>% apply(2, function(x){ 100 * sum(x>Min_abundance)/length(x)  } ) -> More_than_10perc_abund
  Early %>% select(NG_ID, names(More_than_10perc_abund[More_than_10perc_abund>=PercentageSamples] ) ) -> Early_filt
  return( list(Early_filt, Prevalence) )
}


Do_Genus = F

Filter_names(Early, Do_Genus) -> Early
```
Let's make a quick comparison between both abundance profiles
```{r,  warning=FALSE, message=FALSE}
Filter_names(df %>% filter(NG_ID %in% InfoEarly$NG_ID), Do_Genus) -> Early1
Filter_names(df2_3 %>% filter(NG_ID %in% InfoEarly$NG_ID), Do_Genus) -> Early2

Early1 %>% filter(NG_ID %in% Early2$NG_ID) %>% arrange(NG_ID) -> Early1
Early2 %>% filter(NG_ID %in% Early1$NG_ID) %>% arrange(NG_ID) -> Early2

colnames(Early1)[!colnames(Early1) %in% colnames(Early2)] %>% length()
colnames(Early2)[!colnames(Early2) %in% colnames(Early1)] %>% length()

Filter_XAbundance_in_YPrevalence(Early1)[[1]] -> Early1_2
Filter_XAbundance_in_YPrevalence(Early2)[[1]] -> Early2_2

colnames(Early1_2)[!colnames(Early1_2) %in% colnames(Early2_2)] %>% length()
colnames(Early2_2)[!colnames(Early2_2) %in% colnames(Early1_2)] %>% length()

Early1_2 %>% select(-one_of("NG_ID")) %>%  vegdist(method = "bray") -> Dist_comp1
Early2_2 %>% select(-one_of("NG_ID")) %>%  vegdist(method = "bray") -> Dist_comp2
mantel(Dist_comp2, Dist_comp2)

PCoACheck=cmdscale(Dist_comp1, k = 20, eig = T)
PCoACheck2=cmdscale(Dist_comp2, k = 20, eig = T)

cor(as_tibble(PCoACheck$points)$V1, as_tibble(PCoACheck2$points)$V1)
cor(as_tibble(PCoACheck$points)$V2, as_tibble(PCoACheck2$points)$V2)
cor(as_tibble(PCoACheck$points)$V3, as_tibble(PCoACheck2$points)$V3)

```

Filtering based on abundance and prevalence
```{r, warning=FALSE, message=FALSE}
Min_abundance = 0.1 # Abundance bigger than 0.1%
PercentageSamples = 10 #In 10% samples

Filter_XAbundance_in_YPrevalence(Early, Min_abundance, PercentageSamples) -> R ; R[[1]] -> Early_filt ; R[[2]] -> Prevalence 

my_pseudocount_normal=min(select(Early_filt, -NG_ID)[select(Early_filt, -NG_ID)!=0])/2

InfoEarly %>% left_join(Early_filt) %>% drop_na() -> InfoEarly
#Input data early timepoint
InfoEarly %>% select(colnames(Early_filt)) %>% select(-NG_ID)   -> Early_filt
```


##3. Clustering
We will start with some visualizations

Start with preparations
```{r, warning=FALSE, message=FALSE}
set.seed(123)

Prevalence %>% filter(Prev > 0) -> Remove0s
Early %>% select(Remove0s$Taxa) -> Early_complete
#CLR-transform rel. abundances
CRL_taxa = decostand(Early_filt %>% select(-one_of("NG_ID")), 'clr', pseudocount=my_pseudocount_normal)
```
Make plots
```{r, warning=FALSE, message=FALSE}
#Correlation taxa
CRL_taxa  %>% cor()  %>% pheatmap::pheatmap(show_rownames = FALSE, main = "SGB-SGB correlation (CLR)")
#Visualization taxa and infants
CRL_taxa  %>% pheatmap::pheatmap(show_rownames = FALSE, main = "Infant clustering and SGB clustering (CLR)")
#Visualize infant groups
CRL_taxa %>% vegdist(method = "euc") %>% pheatmap::pheatmap(show_rownames = FALSE, main="Infant clustering (CLR)")
#Not CLR transformed
Early_filt %>% select(-one_of("NG_ID")) %>% cor() %>% pheatmap::pheatmap(show_rownames = FALSE, main = "SGB-SGB correlation (Rel abund)")
Early %>% select(-one_of("NG_ID")) %>%  vegdist(method = "bray") %>% pheatmap::pheatmap(show_rownames = FALSE, main="Infant clustering and SGB clustering (bray)")
Early_filt %>% select(-one_of("NG_ID")) %>% pheatmap::pheatmap(show_rownames = FALSE, main="Infant clustering and SGB clustering (Rel abund)")
```
Clustering based on bray-curtis distance. 
```{r, warning=FALSE, message=FALSE}
set.seed(987)
Bray = vegdist(Early_filt, "bray")
hc <- hclust(Bray)
hcRange <- as.clustrange(hc, diss=Bray, ncluster=20)

#If PAM clustering
#wcKMedRange(Bray, kvals=2:20) -> res2
#plot(res2, norm="zscore")


#ASW: Average Silhouette Width
#CH: CalinskiHarabasz index
hcRange[[3]] %>% as.data.frame() %>% rownames_to_column("Cluster") %>% as_tibble() %>% mutate(Cluster = as.factor(as.numeric(str_replace(Cluster, "cluster","")))) -> Scores
#res2[[4]]%>% as.data.frame() %>% rownames_to_column("Cluster") %>% as_tibble() %>% mutate(Cluster = as.factor(as.numeric(str_replace(Cluster, "cluster","")))) -> Scores

Scores %>% dplyr::select(Cluster, ASW, CH, CHsq,R2) %>% gather(Index, Value, c(ASW, CH, CHsq, R2)) %>% ggplot(aes(x=Cluster, y=Value)) + geom_point() + coord_flip() + facet_wrap(~Index, scales = "free") +theme_bw()

#summary(hcRange, max.rank=3)
#summary(res2, max.rank=3)

hcRange$clustering %>% mutate(NG_ID = InfoEarly$NG_ID) %>% select(NG_ID, cluster8) %>% rename(Hier_cluster = cluster8) -> hClustClusters
InfoEarly %>% left_join(hClustClusters) -> InfoEarly

InfoEarly %>% select("NG_ID",colnames(Early_filt)) %>% as.data.frame() %>% column_to_rownames("NG_ID") %>% pheatmap::pheatmap(show_rownames = FALSE, main="Infant clustering and SGB clustering (relAbu)", annotation_row = hClustClusters %>% as.data.frame() %>% column_to_rownames("NG_ID"), cluster_rows=hc   )

```

Try different clustering methods
```{r, warning=FALSE, message=FALSE}
#Do_on = "AST" #"CRL"
Do_on = "relAbundance"

Calculate_stats = function(df, score="both" ){
  set.seed(88765)
  Results = list()
  Pos = 1
  if (score == "gap" | score == "both"  ){
    clusGap(df, FUNcluster = kmeans, K.max = 15) %>%  factoextra::fviz_gap_stat(.) -> cluster_stat
    Gap_kmeans = cluster::maxSE(cluster_stat$data$gap, cluster_stat$data$SE.sim)
    
    clusGap(df, FUNcluster = pam, K.max = 15) %>%  factoextra::fviz_gap_stat(.) -> cluster_stat
    Gap_pam = cluster::maxSE(cluster_stat$data$gap, cluster_stat$data$SE.sim)
    
    Results[[Pos]] = Gap_kmeans
    names(Results)[Pos] = "Gap_kmeans"
    Pos + 1 -> Pos
    Results[[Pos]] = Gap_pam
    names(Results)[Pos] = "Gap_pam"
    Pos + 1 -> Pos
  }
  if (score == "sil" | score == "both"  ){
    factoextra::fviz_nbclust(df, FUNcluster = kmeans, k.max = 10) -> cluster_stat
    Sil_kmeans =  head(arrange(cluster_stat$data, desc(y)), 1)$clusters
    factoextra::fviz_nbclust(CRL_taxa, FUNcluster = pam, k.max = 10,) -> cluster_stat
    Sil_pam =  head(arrange(cluster_stat$data, desc(y)), 1)$clusters
     
    Results[[Pos]] = Sil_kmeans
    names(Results)[Pos] = "Sil_kmeans"
    Pos + 1 -> Pos
    Results[[Pos]] = Sil_pam
    names(Results)[Pos] = "Sil_pam"
    Pos + 1 -> Pos
  }
  
  return(Results)
}


if (Do_on == "CRL"){

  ##WARNING: optimal value may change depending on whether working with SGB / genus  and filtering options
  
  set.seed(889)
  CRL_taxa %>% Calculate_stats(score = "both") -> Clusters_CRL
  print(Clusters_CRL)
  #kmeans using Gap score
  CRL_taxa %>% kmeans(Clusters_CRL[["Gap_kmeans"]]) -> Cluster1
  #pam using gap score
  CRL_taxa %>% pam(Clusters_CRL[["Gap_pam"]]) -> Cluster2

  #Attach
  InfoEarly %>% mutate(Cluster_kmean = Cluster1$cluster, Cluster_kmedian = Cluster2$cluster, .before=4  ) -> InfoEarly

  
  CRL_taxa %>% mutate(NG_ID = InfoEarly$NG_ID) %>% select("NG_ID",colnames(Early_filt)) %>% as.data.frame() %>% column_to_rownames("NG_ID") %>%  pheatmap::pheatmap(show_rownames = FALSE, main="Infant clustering and SGB clustering (CLR)", annotation_row = InfoEarly %>% as.data.frame() %>% column_to_rownames("NG_ID") %>% mutate(Cluster_kmean = as.factor(Cluster_kmean), Cluster_kmedian=as.factor(Cluster_kmedian) ) %>%  select(Cluster_kmean, Cluster_kmedian)  )
  
  #Other clusterings
  #fuzzy clusering (allows for each sample to be assign with a probability value to multiple clusters): m controls fuzzines, if close to 1, less fuzzy (exact assignment), if larger, the more fuzzy the clusers become
  #fclust::FKM(CRL_taxa,  index = "SIL.F", 2:10, stand = 0, RS=1, seed=9877, m = 1.8 ) -> fuzzzy_clusters
  #summary(fuzzzy_clusters)
  #DirichletMultinomial. 
  #library(DirichletMultinomial)
  #fit <- mclapply(1:7, dmn, count=as.matrix(Early_complete), verbose=TRUE, mc.cores = 7)
  #lplc <- sapply(fit, laplace)
  #ggplot() + geom_point(aes(y=lplc, x=seq(1:7))) +theme_bw()
}else if (Do_on == "relAbundance"){
  Bray = vegan::vegdist(Early_filt %>% select(-one_of("NG_ID")))
  fpc::cluster.stats(d=Bray, clustering=seq(1:4) )
  
  set.seed(889)
  Early_filt %>% select(-one_of("NG_ID")) %>% Calculate_stats(score = "both") -> Clusters_relAbu
  print(Clusters_relAbu)
  #kmeans using Gap score
  Early_filt %>% select(-one_of("NG_ID")) %>% kmeans(Clusters_relAbu[["Gap_kmeans"]]) -> Cluster1
  #pam using gap score
  Early_filt %>% select(-one_of("NG_ID")) %>%  pam(Clusters_relAbu[["Gap_pam"]]) -> Cluster2

  InfoEarly %>% mutate(Cluster_kmean = Cluster1$cluster, Cluster_kmedian = Cluster2$cluster, .before=4  ) -> InfoEarly

  InfoEarly %>% select("NG_ID",colnames(Early_filt)) %>% as.data.frame() %>% column_to_rownames("NG_ID") %>% pheatmap::pheatmap(show_rownames = FALSE, main="Infant clustering and SGB clustering (relAbu)", annotation_row = InfoEarly %>% as.data.frame() %>% column_to_rownames("NG_ID") %>% mutate(Cluster_kmean = as.factor(Cluster_kmean), Cluster_kmedian=as.factor(Cluster_kmedian) ) %>%  select(Cluster_kmean, Cluster_kmedian)  )

} else if (Do_on == "AST"){
  set.seed(889)
  Early_filt %>% select(-one_of("NG_ID")) %>% apply(2, AST_transform) %>% Calculate_stats(score = "both") -> Clusters_AST
  print(Clusters_AST)
  #kmeans using Gap score
  Early_filt %>% select(-one_of("NG_ID")) %>% apply(2, AST_transform) %>% kmeans(Clusters_AST[["Gap_kmeans"]]) -> Cluster1
  #pam using gap score
  Early_filt %>% select(-one_of("NG_ID")) %>% apply(2, AST_transform) %>%  pam(Clusters_AST[["Gap_pam"]]) -> Cluster2

  InfoEarly %>% mutate(Cluster_kmean = Cluster1$cluster, Cluster_kmedian = Cluster2$cluster, .before=4  ) -> InfoEarly

  InfoEarly %>% select("NG_ID",colnames(Early_filt)) %>% as.data.frame() %>% column_to_rownames("NG_ID") %>% apply(2, AST_transform)   %>% pheatmap::pheatmap(show_rownames = FALSE, main="Infant clustering and SGB clustering (ASV)", annotation_row = InfoEarly %>% as.data.frame() %>% column_to_rownames("NG_ID") %>% mutate(Cluster_kmean = as.factor(Cluster_kmean), Cluster_kmedian=as.factor(Cluster_kmedian) ) %>%  select(Cluster_kmean, Cluster_kmedian)  )
  
}


```

##4. Do PCoA analysis
```{r, warning=FALSE, message=FALSE}
Distance = "Ait"
Distance = "Bray"
if (Distance == "Ait"){
  Early_filt %>% select(-one_of("NG_ID")) %>% vegdist(method = 'aitchison', pseudocount=my_pseudocount_normal ) -> Dist
}else if (Distance == "Bray"){
  Early_filt %>% select(-one_of("NG_ID")) %>% vegdist(method = 'bray' ) -> Dist
}
mypcoa_CLR=cmdscale(Dist, k = 20, eig = T)
mypcoa_CLR$points %>% as_tibble() %>% cbind(InfoEarly, . ) %>% as_tibble() %>% dplyr::rename(PC1 = V1, PC2 = V2, PC3 =V3, PC4=V4, PC5 = V5)  -> PC_early
Percn_var = round(100*(mypcoa_CLR$eig/sum(mypcoa_CLR$eig)), 2)
ggplot() + geom_bar(aes(y=Percn_var[1:20], x=seq(1:20 ) ), stat = "identity") + theme_bw() +xlab("Component") + ylab("Variance (%)")

```
Plot PCoA
```{r, warning=FALSE, message=FALSE}
Plot_function = function( PC_early , Show_cluster = F, Bacteria = NA, Cluster = "Cluster_kmean", X="PC1", Y="PC2",Percn_v =Percn_var, Shape = NA ){
  if (Cluster %in% colnames(PC_early) ){ PC_early[, Cluster] = as.factor( as_vector(PC_early[, Cluster]))  }
  N_col = length(unique(as_vector(PC_early[,Cluster])))
  
  ##WITHOUT BACTERIA COLOR###
  if ( is.na (Bacteria )){
    #NO COLOR CLUSTERS
    if (Show_cluster == F){
        if ( is.na(Shape) ) {
      PC_early %>% ggplot(aes_string(x=X, y=Y)) + geom_point() + theme_bw() + xlab( paste0(X,"(",Percn_v[as.numeric(substring(X, 3, 3))], "%)") ) + ylab( paste0(Y,"(",as.numeric(substring(Y, 3, 3)), "%)") ) +   scale_color_manual(values  = brewer.dark2(N_col))
        } else {
        PC_early %>% ggplot(aes_string(x=X, y=Y, shape=Shape)) + geom_point() + theme_bw() + xlab( paste0(X,"(",Percn_v[as.numeric(substring(X, 3, 3))], "%)") ) + ylab( paste0(Y,"(",Percn_v[as.numeric(substring(Y, 3, 3))], "%)") ) +   scale_color_manual(values  = brewer.dark2(N_col)) 
        }
    #COLOR CLUSTERS  
    }else{
      if ( is.na(Shape) ) {
      PC_early %>% ggplot(aes_string(x=X, y=Y, col=Cluster)) + geom_point() + theme_bw() + xlab( paste0(X,"(",Percn_v[as.numeric(substring(X, 3, 3))], "%)") ) + ylab( paste0(Y,"(",Percn_v[as.numeric(substring(Y, 3, 3))], "%)") ) +   scale_color_manual(values  = brewer.dark2(N_col))
      } else {
        PC_early %>% ggplot(aes_string(x=X, y=Y, col=Cluster, shape=Shape)) + geom_point() + theme_bw() + xlab( paste0(X,"(",Percn_v[as.numeric(substring(X, 3, 3))], "%)") ) + ylab( paste0(Y,"(",Percn_v[as.numeric(substring(Y, 3, 3))], "%)") ) +   scale_color_manual(values  = brewer.dark2(N_col))
      } }
  ##WITH BACTERIA COLOR###
  }else{
  if (! Bacteria %in% colnames(PC_early) ){ Bacteria = str_replace(Bacteria, "\\.", "\\|") }
  if (Show_cluster == F){
      PC_early %>% ggplot(aes_string(x=X, y=Y, col=paste0("`",Bacteria, "`") )) + geom_point() + theme_bw() + scale_color_viridis(direction = -1) + new_scale_color() + xlab( paste0(X,"(",Percn_var[as.numeric(substring(X, 3, 3))], "%)") ) + ylab( paste0(Y,"(",Percn_var[as.numeric(substring(Y, 3, 3))], "%)") ) +   scale_color_manual(values  =brewer.dark2(N_col))
  }else{  
    PC_early %>% ggplot(aes_string(x=X, y=Y, col=paste0("`",Bacteria, "`") )) + geom_point() + theme_bw() + scale_color_viridis(direction = -1) + new_scale_color()  + stat_ellipse(aes_string(col=Cluster), type = "t") + xlab( paste0(X,"(",Percn_var[as.numeric(substring(X, 3, 3))], "%)") ) + ylab( paste0(Y,"(",as.numeric(substring(X, 3, 3)), "%)") ) +   scale_color_manual(values  = brewer.dark2(N_col))
  }
  }  
}
C = "Hier_cluster"
#C = "Cluster_kmedian"

Plot_function(PC_early, Show_cluster = T, Bacteria = NA, X="PC1", Y="PC2", Cluster = C )
Plot_function(PC_early, Show_cluster = T, Bacteria = NA, X="PC1", Y="PC3", Cluster = C )
Plot_function(PC_early, Show_cluster = T, Bacteria = NA, X="PC1", Y="PC4", Cluster = C )


Show = T
if (Do_Genus == T ){
  Plot_function(PC_early, Show_cluster = Show, Bacteria = "g__Escherichia", Cluster = C ) -> P1
  Plot_function(PC_early, Show_cluster = Show, Bacteria = "g__Bifidobacterium", Cluster =C ) -> P2
  Plot_function(PC_early, Show_cluster = Show, Bacteria = "g__Bacteroides", Cluster= C ) -> P3
  P1 / P2 /P3 + plot_layout(guides = "collect") 
} else {
  Plot_function(PC_early, Show_cluster = Show, Bacteria = "Escherichia_coli.t__SGB10068", Cluster = C ) %>% print()
  Plot_function(PC_early, Show_cluster = Show, Bacteria = "Bifidobacterium_bifidum.t__SGB17256", Cluster = C ) %>% print()
  if ( "Bifidobacterium_longum.t__SGB17248" %in% colnames(PC_early) ){
    Plot_function(PC_early, Show_cluster = Show, Bacteria = "Bifidobacterium_longum.t__SGB17248", Cluster = C ) %>% print()
    Plot_function(PC_early, Show_cluster = Show, Bacteria = "Bacteroides_fragilis.t__SGB1855_group",Cluster = C ) %>% print()
  } else {
    Plot_function(PC_early, Show_cluster = Show, Bacteria = "Bifidobacterium_longum.t__subsp.longum",Cluster = C  ) %>% print()
      Plot_function(PC_early, Show_cluster = Show, Bacteria = "Bacteroides_fragilis.t__SGB1855", Cluster = C ) %>% print()

  }
  Plot_function(PC_early, Show_cluster = Show, Bacteria = "Bifidobacterium_breve.t__SGB17247", Cluster = C ) %>% print()
  Plot_function(PC_early, Show_cluster = Show, Bacteria = "Phocaeicola_dorei.t__SGB1815", Cluster = C, Y="PC3" ) %>% print()
}
```
Plot boxplots of taxa per clusters
```{r, warning=FALSE, message=FALSE}
PC_early[C] = as.factor(as_vector(PC_early[C]))
Bugs_interst = c( "Escherichia_coli.t__SGB10068",  "Bifidobacterium_bifidum.t__SGB17256", "Bifidobacterium_longum.t__SGB17248", "Bifidobacterium_breve.t__SGB17247", "Bacteroides_fragilis.t__SGB1855_group",  "Phocaeicola_dorei.t__SGB1815", "Bifidobacterium_longum|t__subsp.infantis")
Allplots = list()
N = 1
for (Bug in c(colnames(Early_filt),"Bifidobacterium_longum.t__subsp.infantis")  ){
  if (Bug %in% colnames(PC_early)){
    PC_early %>% ggplot(aes_string(x=C, y=Bug ) ) + geom_boxplot(outlier.shape = NA) + geom_point() +theme_bw() -> plot
  } else {
   Filter_names(df2_3, Do_Genus = F) %>% select(c("NG_ID", Bug)) %>% left_join(PC_early, . ) %>% ggplot(aes_string(x=C, y=Bug ) ) + geom_boxplot(outlier.shape = NA) + geom_point() +theme_bw() ->plot
  }
  Allplots[[N]] = plot
  names(Allplots)[N] = Bug
  N = N + 1
  #print(plot)
}

Early_filt  %>% apply(2, AST_transform) %>% as_tibble() %>% mutate(Cluster = as_vector(PC_early[C]) )%>%  group_by(Cluster) %>% summarise(across(where(is.numeric), median, na.rm = TRUE)) %>% select(-Cluster) %>% pheatmap::pheatmap()
Allplots["Bifidobacterium_longum.t__subsp.infantis"]

```
Check which bugs correlate with each Cluster
```{r, warning=FALSE, message=FALSE}

Association_cluster = tibble()

#CRL_taxa %>% mutate(Cluster =  InfoEarly$Cluster_kmedian, exact_age_days_at_collection = InfoEarly$exact_age_days_at_collection) -> InputModel
CRL_taxa %>% mutate(Cluster =  as_vector(InfoEarly[C]), exact_age_days_at_collection = InfoEarly$exact_age_days_at_collection) -> InputModel

for (i in colnames(Early_filt)){
  if (i == "NG_ID"){ next }
  Formula = as.formula( paste0( "`", i , "` ~ as.factor(Cluster) + exact_age_days_at_collection" )  )
  lm(Formula, InputModel) %>% summary() -> D
  D$coefficients %>% as.data.frame() %>% rownames_to_column("Feature") %>% mutate(SGB = i ) %>% rbind(Association_cluster, . ) %>% as_tibble()  -> Association_cluster
  
}

Association_cluster %>% filter(! Feature == "(Intercept)" ) %>% arrange(`Pr(>|t|)`) %>% mutate(FDR = p.adjust(`Pr(>|t|)`, "fdr")) %>% filter(Estimate > 0) 
```




##5. Clustering prediction
```{r, warning=FALSE, message=FALSE}
read_tsv("~/Documents/PhD/LL_NEXT/Transmission/metadata/LLNEXT_metadata_03_01_2024.txt") %>% 
  select(NG_ID, NEXT_ID, Timepoint_categorical, exact_age_days_at_collection, Type, FAMILY) -> metadata_long
Order_time = c("P12", "P28", "B", "W2", "M1", "M2", "M3", "M6", "M9", "M12")
metadata_long %>% mutate(Timepoint_categorical = factor(Timepoint_categorical, levels = Order_time)) -> metadata_long
as_vector(PC_early[C]) %>% table()
```

###5.1 Using late timepoints

```{r, warning=FALSE, message=FALSE}

metadata_long %>% filter(Timepoint_categorical %in% c("M6", "M9", "M12") ) -> Late

#Can we predict which cluster where in W2 using lat timepoints?
df2_3 %>% filter(NG_ID %in% Late$NG_ID ) %>% Filter_names(Do_Genus = F) -> sp_df_late
Late %>% left_join(PC_early %>% select(NEXT_ID, !!sym(C)) ) %>% drop_na() -> Late_with_info
#Get prevalence
sp_df_late %>% select(-NG_ID) %>% apply(2, function(x){ sum(x!=0)/length(x) } ) -> Prev_analysis
names(Prev_analysis)[Prev_analysis>0.2] -> Prev_analysis

ForAnalysis = left_join(Late_with_info,sp_df_late)
Models = list()
N = 1
for (Cl in unique( as_vector(ForAnalysis[C]) ) ){
  if (Cl %in% c(7, 8) ){ next }
  print(Cl)
  ForAnalysis %>% mutate(Cluster = ifelse( !!sym(C) ==Cl, T, F), .before=1 ) -> ForAnalysis2
  ForAnalysis2 %>% group_by(NEXT_ID) %>% summarise(N = n()) %>% filter(N == 1) -> ToRemove
  ForAnalysis2 %>% filter(!NEXT_ID %in% ToRemove$NEXT_ID) %>% drop_na() -> ForAnalysis2
  coda_glmnet_longitudinal(x = ForAnalysis2 %>% dplyr::select(Prev_analysis)  %>% as.matrix()  , y=ForAnalysis2$Cluster, x_time=ForAnalysis2$exact_age_days_at_collection, subject_id =ForAnalysis2$NEXT_ID,  nfolds = 5, ini_time=178, end_time = 387 ) -> Model_cluster
  Models[[N]] = Model_cluster
  names(Models)[N] = Cl
  N = N + 1
}
Scores = tibble()
for (Entry in names(Models)){
 print(Entry)
 print(Models[[Entry]]$`mean cv-AUC`)
 Scores %>% rbind(tibble(Cluster = Entry, CVAUC = Models[[Entry]]$`mean cv-AUC`   )) -> Scores
}
print(gt::gt(arrange(Scores, desc(CVAUC) )))
Scores %>% arrange(desc(CVAUC)) %>% head(1) -> N 
Association_cluster %>% filter(! Feature == "(Intercept)" ) %>% arrange(`Pr(>|t|)`) %>% mutate(FDR = p.adjust(`Pr(>|t|)`, "fdr")) %>% filter(Feature == paste0("as.factor(Cluster)", N$Cluster ) ) %>% select(-c(Feature, `Std. Error`, `t value`))

#For top result, check individual timepoint signature
Models_cross = list()
N2 = 1
for (Timepoint in c("M6", "M9", "M12") ){
  ForAnalysis %>% mutate(Cluster = ifelse( !!sym(C) ==N$Cluster, T, F), .before=1 ) %>% filter(Timepoint_categorical==Timepoint) %>% drop_na() -> ForAnalysis2
  coda_glmnet(x = ForAnalysis2 %>% dplyr::select(Prev_analysis)  %>% as.matrix()  , y=ForAnalysis2$Cluster,  ) -> Model_cluster
  
  Models_cross[[N2]] = Model_cluster
  names(Models_cross)[N2] = Timepoint
  N2 = N2 + 1
}
Scores2 = tibble()
for (Entry in names(Models_cross)){
 print(Entry)
 print(Models_cross[[Entry]]$`mean cv-AUC`)
 Scores2 %>% rbind(tibble(Cluster = Entry, CVAUC = Models_cross[[Entry]]$`mean cv-AUC`   )) -> Scores2
}
#For Top Timepoint, fit null model
Scores2 %>% arrange(desc(CVAUC)) %>% head(1) -> N2

ForAnalysis %>% mutate(Cluster = ifelse( !!sym(C) ==N$Cluster, T, F), .before=1 ) %>% filter(Timepoint_categorical==N2$Cluster) %>% drop_na() -> ForAnalysis2

null_acc<-coda_glmnet_null(x=ForAnalysis2 %>% dplyr::select(Prev_analysis)  %>% as.matrix(),y=ForAnalysis2$Cluster, niter=100)
Percentage_nullModels = mean(null_acc$accuracy >= N2$CVAUC )

```


###5.2 Using mother timepoints

```{r, warning=FALSE, message=FALSE}
set.seed(1887)

metadata_long %>% filter(Type == "mother" ) -> Mothers
PC_early %>% left_join(metadata_long) %>% select(FAMILY, !!sym(C)) %>% left_join(Mothers) %>% drop_na() -> Mothers
df2_3 %>% filter(NG_ID %in% Mothers$NG_ID ) %>% Filter_names(Do_Genus = F) -> sp_mothers
sp_mothers %>% select(-NG_ID) %>% apply(2, function(x){ sum(x!=0)/length(x) } ) -> Prev_analysis
names(Prev_analysis)[Prev_analysis>0.2] -> Prev_analysis

ForAnalysis = left_join(Mothers,sp_mothers)
ForAnalysis %>% filter(!Timepoint_categorical %in% c("M1", "M2") ) %>% mutate(TimeNumeric = ifelse(Timepoint_categorical == "P12", -24, ifelse(Timepoint_categorical %in% c("P28", "B") , 0, 12  ) )  ) -> ForAnalysis
Models_mother = list()
N = 1
for (Cl in unique(as_vector(ForAnalysis[C]) )){
  if (Cl %in% c(7, 8) ){ next }
  print(Cl)
  ForAnalysis %>% mutate(Cluster = ifelse(!!sym(C)==Cl, T, F), .before=1 ) -> ForAnalysis2
  ForAnalysis2 %>% group_by(NEXT_ID) %>% summarise(N = n()) %>% filter(N == 1) -> ToRemove
  dim(ToRemove)
  ForAnalysis2 %>% filter(!NEXT_ID %in% ToRemove$NEXT_ID) %>% drop_na() -> ForAnalysis2
  coda_glmnet_longitudinal(x = ForAnalysis2 %>% dplyr::select(Prev_analysis)  %>% as.matrix()  , y=ForAnalysis2$Cluster, x_time=ForAnalysis2$TimeNumeric, subject_id =ForAnalysis2$NEXT_ID,  nfolds = 10, ini_time=-24, end_time = 12, showPlots = F ) -> Model_cluster
  Models_mother[[N]] = Model_cluster
  names(Models_mother)[N] = Cl
  N = N + 1
}
Scores_mother = tibble()
for (Entry in names(Models_mother)){
 print(Entry)
 print(Models_mother[[Entry]]$`mean cv-AUC`)
 Scores_mother %>% rbind(tibble(Cluster = Entry, CVAUC = Models_mother[[Entry]]$`mean cv-AUC`   )) -> Scores_mother
}
print(gt::gt(arrange(Scores_mother, desc(CVAUC) )))


Scores_mother %>% arrange(desc(CVAUC)) %>% head(1) -> N 
Association_cluster %>% filter(! Feature == "(Intercept)" ) %>% arrange(`Pr(>|t|)`) %>% mutate(FDR = p.adjust(`Pr(>|t|)`, "fdr")) %>% filter(Feature == paste0("as.factor(Cluster)", N$Cluster ) ) %>% select(-c(Feature, `Std. Error`, `t value`))

Scores_mother %>% arrange(desc(CVAUC)) %>% head(2) %>% tail(1) -> N 
Association_cluster %>% filter(! Feature == "(Intercept)" ) %>% arrange(`Pr(>|t|)`) %>% mutate(FDR = p.adjust(`Pr(>|t|)`, "fdr")) %>% filter(Feature == paste0("as.factor(Cluster)", N$Cluster ) ) %>% select(-c(Feature, `Std. Error`, `t value`))


```


##6. Associate clusters to phenotypes
```{r, warning=FALSE, message=FALSE}
read.delim("~/Documents/PhD/LL_NEXT/Transmission/metadata/masterfile_longitudinal_2023_09_29.txt") %>% as_tibble()  %>% rename(NEXT_ID = next_id_infant ) %>% as_tibble() -> CrossPheno

PC_early %>% left_join(CrossPheno) -> ForAssociation

Run_association = function(ForModel = ForAssociation, Cluster_n=1 ){
  ForModel %>% mutate(Cluster = ifelse(!!sym(C) == Cluster_n, T, F )  ) -> ForModel
  Results_ass = tibble()
  for (Pheno in colnames(CrossPheno) ) {
    if (Pheno %in% colnames(CrossPheno)[1:10] ){ next }
    if (grepl("ffq", Pheno) ){ next }
    #print(Pheno)
    ForModel %>% filter(!is.na(!!sym(Pheno))) -> ForModel2
    if (dim(ForModel2)[1] < 50){ next }
    ####Check levels
    ForModel2 %>% ungroup() %>% group_by(!! sym(Pheno)  ) %>% summarise(N = n()) -> Levels
    if (dim(Levels)[1] < 10 ){
      ForModel2  %>% group_by(!!sym(Pheno), Cluster) %>% summarise(N = n()) -> LevelsCluster
      if (dim(LevelsCluster)[1] < dim(Levels)[1]*2 ){ next 
      } else{
          LevelsCluster %>% filter(N < 20) -> LevelsCluster2
          if (dim(LevelsCluster2)[1] > 0) { next }
        }
    }
    ####
    Formula = paste0( "Cluster ~ ", Pheno )
    glm(Formula, ForModel, family = binomial() ) %>% summary() -> Model1
    tail(as_tibble(Model1$coefficients),1) %>% mutate(Phenotype = Pheno, N = dim(ForModel2)[1], S=dim(LevelsCluster2)[1] )  %>% rbind(Results_ass, . ) -> Results_ass
  }
  return(Results_ass)
}
ResAss = tibble()
for (Cl in unique(as_vector(ForAssociation[C]))){
  print(Cl)
  Run_association(ForModel = ForAssociation, Cluster_n=Cl) %>% mutate(Cluster = Cl) %>% rbind(ResAss, .) -> ResAss
}
ResAss %>% mutate(FDR = p.adjust(`Pr(>|z|)`, "fdr")) %>% arrange(`Pr(>|z|)`) -> ResAss
ResAss %>% select(-c(`Std. Error`, `z value`, `Pr(>|z|)` )) %>% gt::gt() %>% gt::fmt_number(columns = c("Estimate", "FDR"), decimals = 3)
```
Let's visualize this
```{r, warning=FALSE, message=FALSE}
ForAssociation %>% ggplot(aes(x=!!sym(C)==4, infant_growth_HcAZ  )) + geom_boxplot(outlier.shape = NA ) + ggforce::geom_sina(alpha=0.2) + theme_bw() + coord_flip()


ResAss %>% filter(FDR<0.077) -> PhenosCheck

ResAss %>% filter(Phenotype %in% PhenosCheck$Phenotype) %>% select(Cluster, Phenotype,  FDR) %>% mutate(FDR = round(FDR, 4)) %>% spread(Phenotype,  FDR) %>% as.data.frame() %>% column_to_rownames("Cluster") -> Annotation_fdr

ResAss %>% filter(Phenotype %in% PhenosCheck$Phenotype) %>% select(Cluster, Phenotype,  `z value`) %>% spread(Phenotype,  `z value`) %>% as.data.frame() %>% column_to_rownames("Cluster") %>% pheatmap::pheatmap(display_numbers = Annotation_fdr)


```

Do we see ratios of bacteria in the clusters when predicting infant_growth?
```{r, warning=FALSE, message=FALSE}
I = 1
Models_growth = list()
for (Growth_pheno in colnames(ForAssociation)[grepl("infant_growth", colnames(ForAssociation))] ){
  print(Growth_pheno)
  ForAssociation %>% filter(!is.na(!!sym(Growth_pheno))) -> ForAssociation2
  coda_glmnet(x = ForAssociation2 %>% dplyr::select(colnames(Early_filt))  %>% as.matrix(), y=as_vector(ForAssociation2[Growth_pheno])  ) -> GrowthModel
  Models_growth[[I]] = GrowthModel
  names(Models_growth)[I] = Growth_pheno
  I + 1 -> I
} 

Scores_growth = tibble()
for (Entry in names(Models_growth)){
 print(Entry)
 AUC = NA ; MSE=NA
 if ("mean cv-AUC" %in%  names(Models_growth[[Entry]])){  AUC =  Models_growth[[Entry]]$`mean cv-AUC` }
 if ("mean cv-MSE" %in% names(Models_growth[[Entry]])){  MSE =  Models_growth[[Entry]]$`mean cv-MSE` } 
 Scores_growth %>% rbind(tibble(Pheno = Entry, CVAUC = AUC, CVMSE= MSE  )) -> Scores_growth
}
Models_growth[["infant_growth_HcAZ"]]$`signature plot`
Models_growth[["infant_growth_LAZ"]]$`signature plot`

```


# Part 2: B. longum subspecies

##1. Prepare data
```{r, warning=FALSE, message=FALSE}
read_tsv("~/Documents/PhD/LL_NEXT/Transmission/metadata/LLNEXT_metadata_03_01_2024.txt") %>% 
  select(NG_ID, NEXT_ID, Timepoint_categorical, exact_age_days_at_collection, Type, FAMILY) -> metadata_long
Order_time = c("P12", "P28", "B", "W2", "M1", "M2", "M3", "M6", "M9", "M12")
metadata_long %>% mutate(Timepoint_categorical = factor(Timepoint_categorical, levels = Order_time)) -> metadata_long
#Clean MP4 table
Filter_names(df2_3, Do_Genus = F) -> sp_df
#Filter on prevalence. This can/should be improved
sp_df %>% filter(NG_ID  %in% filter(metadata_long, Type!="mother" )$NG_ID ) -> sp_df_infant
sp_df %>% filter(NG_ID  %in% filter(metadata_long, Type=="mother" )$NG_ID ) -> sp_df_mother


sp_df_infant %>% select(-NG_ID) %>% apply(2, function(x){ sum(x!=0)/length(x) } ) -> Prev_infant
names(Prev_infant)[Prev_infant>0.2] -> Prevalent_infant
sp_df_mother %>% select(-NG_ID) %>% apply(2, function(x){ sum(x!=0)/length(x) } ) -> Prev_mother
names(Prev_mother)[Prev_mother>0.2] -> Prevalent_mother


my_pseudocount_normal2=min(select(sp_df, -NG_ID)[select(sp_df, -NG_ID)!=0])/2
#Get only longum subspecies
colnames(sp_df)[grepl("Bifidobacterium_longum",colnames(sp_df) )] -> Longum
metadata_long %>% select(-FAMILY) %>% left_join( select(sp_df, c("NG_ID", Longum)) ) %>% drop_na() -> sp_df2

#CLR transformation
CRL_taxa_l = decostand(sp_df %>% select(-one_of("NG_ID")), 'clr', pseudocount=my_pseudocount_normal2) %>% as_tibble()
CRL_taxa_l %>% mutate(NG_ID = sp_df$NG_ID, .before=1 ) -> CRL_taxa_l 


#Cross-sectional phenotypes
read_tsv("~/Documents/PhD/LL_NEXT/Transmission/metadata/masterfile_cross_sectional_2023_11_15.txt") %>% select(next_id_infant,
mother_birthcardself_gestational_age_weeks, birth_deliverybirthcard_mode_binary,birth_deliverybirthcard_place_delivery_simple,
birth_delivery_mode_simple, birth_delivery_mode_complex,mother_birthcard_parity,family_pets_any, 
infant_birthcard_feeding_mode_after_birth, mother_birthcard_duration_water_broken_min, birth_birthcard_total_duration_delivery_min) -> metadatacross
#longitudinal phenotypes
read.delim("~/Documents/PhD/LL_NEXT/Transmission/metadata/masterfile_longitudinal_2023_09_29.txt") %>% as_tibble() %>%
  select(next_id_infant, SAMPLE_ID, infant_ffq_feeding_mode_simple, infant_ffq_feeding_mode_complex) %>% rename(NEXT_ID = next_id_infant ) %>% as_tibble() %>% drop_na() -> dynamic
left_join(dynamic, metadata_long %>% mutate(SAMPLE_ID = paste0(NEXT_ID,"_",Timepoint_categorical ) )) %>% select(c(NG_ID, colnames(dynamic))) -> dynamic
dynamic$NG_ID = sapply(dynamic$NG_ID, function(x){ str_split(x, "_")[[1]][1] } )


```

Prevalence of infantis per timepoint and mother/infant
```{r , warning=FALSE, message=FALSE}

sp_df2 %>% group_by(Type, Timepoint_categorical ) %>% summarise(Prevalence_infantis = mean(Bifidobacterium_longum.t__subsp.infantis != 0 ), N_samples = n() ) %>% ggplot(aes(x=Timepoint_categorical, y=Prevalence_infantis )) + geom_bar(stat="identity") + theme_bw() +facet_wrap(~Type, scales="free") + geom_text(aes(label = paste("n =", N_samples)), vjust = -0.5, size = 3) 

sp_df2 %>% group_by(Type, Timepoint_categorical ) %>% summarise(Prevalence_longum = mean(Bifidobacterium_longum.t__subsp.longum != 0 ), N_samples = n() ) %>% ggplot(aes(x=Timepoint_categorical, y=Prevalence_longum )) + geom_bar(stat="identity") + theme_bw() +facet_wrap(~Type, scales="free") + geom_text(aes(label = paste("n =", N_samples)), vjust = -0.5, size = 3) 

```

##2. Check mothers with infantis
```{r, warning=FALSE, message=FALSE}
sp_df2 %>% group_by(Type, `Bifidobacterium_longum.t__subsp.infantis`==0 ) %>% summarise(n())

#Check Mothers with infantis
sp_df2 %>% filter(Type == "mother") %>% filter(`Bifidobacterium_longum.t__subsp.infantis`!=0) -> Mothers_with_infantis #; Mothers_with_infantis %>% group_by(NEXT_ID) %>% summarise(n()) 
sp_df2 %>% filter(Type == "mother") %>% filter(NEXT_ID %in% Mothers_with_infantis$NEXT_ID )  %>% gather(Taxa, Rel_abundance, Longum )  %>% ggplot(aes(x=NEXT_ID, y=AST_transform(Rel_abundance), fill=Taxa )) + geom_bar(stat="identity") + theme_bw() + facet_wrap(~Timepoint_categorical) + coord_flip()  +  labs(x = NULL)  + theme(axis.text.y = element_blank()) -> RelAbundanceFig
sp_df2 %>% filter(Type == "mother") %>% filter(NEXT_ID %in% Mothers_with_infantis$NEXT_ID )  %>% gather(Taxa, Rel_abundance, Longum ) %>% ggplot(aes(x=NEXT_ID, y=Rel_abundance, fill=Taxa )) + geom_bar(position="fill",stat="identity") + theme_bw() + facet_wrap(~Timepoint_categorical) + coord_flip() +  labs(x = NULL) + theme(axis.text.y = element_blank()) -> PercFig
(RelAbundanceFig | PercFig)  +  plot_layout(guides = "collect") & theme(legend.position = "bottom")

#Which mothers have infantis in more than 1 timepoint?
Mothers_with_infantis %>% group_by(`Bifidobacterium_longum.t__subsp.infantis` > 0, NEXT_ID) %>% summarise(N = n()) %>% filter(N>1)
#Preavelnece per tiempoint. mothers
sp_df2 %>% filter(Type == "mother")  %>% group_by(Timepoint_categorical ) %>%   summarise(N = n(),prevalence = sum(`Bifidobacterium_longum.t__subsp.infantis` > 0) / n()) %>% ggplot(aes(x=Timepoint_categorical, y =prevalence )) + geom_bar(stat="identity") + theme_bw() +  geom_text(aes(label = paste("n =", N)), vjust = -0.5, size = 3) 
#distribution rel. abundance mother
sp_df2 %>% filter(Type == "mother") %>% filter(NEXT_ID %in% Mothers_with_infantis$NEXT_ID )  %>% gather(Taxa, Rel_abundance, Longum ) %>% filter(!grepl("unclassified", Taxa)) %>% ggplot(aes(x=AST_transform(Rel_abundance), fill=Taxa)) + geom_histogram(alpha = 0.3) + facet_wrap(~Timepoint_categorical, scales = "free") + theme_bw()
```
##3. Check infantis prevalence in different timepoints
```{r, warning=FALSE, message=FALSE}
#Check infants in different timepoitns
sp_df2 %>% filter(Type == "infant") %>% mutate(Infantis_present = ifelse(`Bifidobacterium_longum.t__subsp.infantis`!=0, 1, 0) ) -> sp_infant
CRL_taxa_l %>% select("NG_ID",Prevalent_infant) %>% filter(NG_ID %in% sp_infant$NG_ID)  %>% left_join( select(sp_infant, c(NG_ID, Infantis_present)) )  -> CRL_taxa_l2
metadata_long %>% left_join(CRL_taxa_l2) %>% drop_na() -> CRL_taxa_l2


sp_infant %>% group_by(Timepoint_categorical) %>% summarise(Perc_infantis = mean(Infantis_present)  ) -> Perc_infantis
Perc_infantis %>% ggplot(aes(x=Timepoint_categorical, y =Perc_infantis  ))+ geom_bar(stat="identity") + theme_bw()
sp_infant %>%  gather(Taxa, Rel_abundance, Longum ) %>% ggplot(aes(x=Timepoint_categorical, y=Rel_abundance ) ) + geom_boxplot(outlier.shape = NA) + ggforce::geom_sina(alpha=0.3) + theme_bw() + facet_wrap(~Taxa, scales = "free") + coord_flip()
```
###3.1 Drop down unclassified. Break down per feeding mode. 
```{r, warning=FALSE, message=FALSE}
sp_infant %>%  gather(Taxa, Rel_abundance, Longum ) %>% left_join(dynamic ) %>% drop_na() %>% filter(!grepl("unclassified", Taxa)) %>% ggplot(aes(x=Timepoint_categorical, y=Rel_abundance, col= infant_ffq_feeding_mode_complex ) ) + geom_boxplot(outlier.shape = NA) + ggforce::geom_sina(alpha=0.3) + theme_bw() + facet_wrap(~Taxa, scales = "free") + coord_flip() + theme(legend.position = "bottom")

sp_infant%>% left_join(dynamic ) %>% filter(! is.na(infant_ffq_feeding_mode_complex)) %>% group_by(Timepoint_categorical, infant_ffq_feeding_mode_complex ) %>% summarise(Prevalence_infantis = mean(Bifidobacterium_longum.t__subsp.infantis != 0) , Prevalence_longum=mean(Bifidobacterium_longum.t__subsp.longum != 0),N_samples = n() ) %>%  gather( Subspecies, Prevalence, c(Prevalence_infantis,Prevalence_longum) )  %>% ggplot(aes(x = Timepoint_categorical, y = Prevalence, fill = infant_ffq_feeding_mode_complex)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9)) +
  geom_text(aes(label = paste("n =", N_samples)), hjust = 1, size = 3, position = position_dodge(width = 0.9)) +
  theme_bw() +
  facet_wrap(~Subspecies, scales = "free") +
  coord_flip() +
  theme(legend.position = "bottom")

  

```
###3.2 Per infant, calculate its total prevalence, compare to its rel. abundance
```{r, warning=FALSE, message=FALSE}
sp_infant %>% group_by(NEXT_ID) %>% summarise( Prevalence_infantis = mean(Infantis_present), Infantis_medianAbundance=median(`Bifidobacterium_longum.t__subsp.infantis`),  N = n()  ) %>% mutate(AST_medianAbundance = AST_transform(Infantis_medianAbundance)  ) -> I_plot
I_plot %>% ggplot(aes(x=Prevalence_infantis, y =AST_medianAbundance, size=N)) + geom_point(alpha=0.5) + theme_bw()                                                 
                                                 #left_join(select(sp_infant, c("NEXT_ID", "Bifidobacterium_longum.t__subsp.infantis","Timepoint_categorical" ,"Infantis_present", "NG_ID"  )) ) %>% left_join( sp_df_infant %>% select(NG_ID, `Bifidobacterium_breve.t__SGB17247`) ) -> I_plot
#I_plot %>% ggplot(aes(x = Prevalence_infantis, y = AST_transform(`Bifidobacterium_longum.t__subsp.infantis`))) + geom_point() + theme_bw()


I_plot %>% ggplot(aes(x=`Bifidobacterium_longum.t__subsp.infantis`, y=`Bifidobacterium_breve.t__SGB17247` )) + geom_point() + theme_bw() + facet_wrap(~Timepoint_categorical)
I_plot %>% ggplot(aes(x = as.factor(Prevalence_infantis), y = AST_transform(`Bifidobacterium_breve.t__SGB17247`))) + geom_point() + geom_boxplot(outlier.shape = NA ) +  theme_bw() + coord_flip()

#Infantis vs breve, presence/absence comparison
sp_infant %>% left_join( sp_df_infant %>% select(NG_ID, `Bifidobacterium_breve.t__SGB17247`) ) %>% mutate(Breve_present = ifelse(`Bifidobacterium_breve.t__SGB17247` > 0 , 1, 0) ) %>% select(NEXT_ID, Timepoint_categorical, Infantis_present, Breve_present, `Bifidobacterium_breve.t__SGB17247`, `Bifidobacterium_longum.t__subsp.infantis`) -> Infantis_vs_Breve
Infantis_vs_Breve %>% group_by(Timepoint_categorical, Infantis_present, Breve_present) %>% summarise(N = n()) %>% mutate(ID = paste0(Infantis_present,Breve_present)  ) %>%  ggplot(aes(x=ID, y=N )) + geom_bar(stat="identity") + facet_wrap(~Timepoint_categorical) + theme_bw()
Phi_table = tibble()
Threshold = 0.2
for (timepoint in unique(Infantis_vs_Breve$Timepoint_categorical) ){
  Infantis_vs_Breve %>% mutate(Breve_present = ifelse(`Bifidobacterium_breve.t__SGB17247`>Threshold, 1, 0 ) , Infantis_present=ifelse(`Bifidobacterium_longum.t__subsp.infantis`>Threshold, 1, 0 ) ) -> Infantis_vs_Breve2
  
  Infantis_vs_Breve2 %>% filter(Timepoint_categorical == timepoint) -> data_tp 
  cor(data_tp$Infantis_present, data_tp$Breve_present) -> Cor
  table(data_tp$Infantis_present, data_tp$Breve_present) -> res
  #print(res)
  res %>% psych::phi() -> res
  tibble(Timepoint = timepoint, Phi = res, Cor_coef = Cor) %>% rbind(Phi_table, .) -> Phi_table
}
#Just presence has an okay correlation. If you go for higher abydbabces, then they dont really correlate
  
```
###3.3 Do infants who have infantis at one timepoint tend to lose it?
```{r, warning=FALSE, message=FALSE}
Exlore_infantis_gainandloss = function(sp_infant, ID_column = "NEXT_ID", Timpeoint_column = "Timepoint_categorical", Threshold = 0  ){
  GainLoss = tibble()
  for (Baby in unique(as_vector(sp_infant[ID_column]) )){
    sp_infant %>% filter(!!sym(ID_column) == Baby ) -> Infantx
    Infantx %>% arrange(!!sym(Timpeoint_column)) -> Infantx
    Infantx %>% mutate(Infantis_present = ifelse( `Bifidobacterium_longum.t__subsp.infantis` > Threshold, 1, 0 )) -> Infantx

    transitions <- diff(Infantx$Infantis_present)
    
    gain_indices <- which(transitions == 1) + 1
    loss_indices <- which(transitions == -1) + 1
    
    gain_timepoints <- as_vector(Infantx[Timpeoint_column])[gain_indices]
    loss_timepoints <-  as_vector(Infantx[Timpeoint_column])[loss_indices]
    
    tibble(NEXT_ID = Baby, N_gain = length(gain_timepoints), N_loss = length(loss_timepoints), gain_timepoints=paste(gain_timepoints, collapse=","), loss_timepoints=paste(loss_timepoints, collapse=","), TimesPointsN=dim(Infantx)[1], Timepoints=paste( as_vector(Infantx[Timpeoint_column]), collapse = ",")  ) %>% rbind(GainLoss, . ) -> GainLoss
  }
  return(GainLoss)
}
Plot_gain_loss = function(GainLoss, ORDER=Order_time ){
  #Check frquency of losses per timepoint
GainLoss$loss_timepoints %>% sapply(function(x){str_split(x, ",")[[1]]  } ) %>% unlist() %>% as_tibble() %>% filter(!value == "") %>% mutate(Timepoint = factor(value, levels=ORDER) ) %>%  ggplot(aes(x=Timepoint)) + geom_bar() +theme_bw() + ggtitle("Time Points where B. longum\n infantis is lost") -> Lost_freq
GainLoss$gain_timepoints %>% sapply(function(x){str_split(x, ",")[[1]]  } ) %>% unlist() %>% as_tibble()  %>% filter(!value == "") %>% mutate(Timepoint = factor(value, levels=ORDER) ) %>% ggplot(aes(x=Timepoint)) + geom_bar() +theme_bw() +
   ggtitle("Time Points where B. longum\n infantis is gained") -> gained_freq
Lost_freq | gained_freq
  
  
}

GainLoss=Exlore_infantis_gainandloss(sp_infant)
#do the same but with a minimum abundance of 0.1
GainLoss2 = Exlore_infantis_gainandloss(sp_infant, Threshold = 0.1)


#How frequenct are Longum gains observed
GainLoss %>% group_by(N_gain) %>% summarise(n())
#How frequent are lossess
GainLoss %>% group_by(N_loss) %>% summarise(n())
#And if we remove late timepoints?
GainLoss %>% filter(! (grepl("M12", loss_timepoints) | grepl("M12", gain_timepoints) )  ) %>% group_by(N_gain) %>% summarise(n())
GainLoss %>% filter(! (grepl("M12", loss_timepoints) | grepl("M12", gain_timepoints) )  ) %>% group_by(N_loss) %>% summarise(n())
#Check frquency of losses per timepoint
Plot_gain_loss(GainLoss, Order_time)


#Do the  oens that start with infantis tend to loss it?
sp_infant %>% filter(Timepoint_categorical == "M2", Infantis_present == T) -> WithIt
GainLoss %>% filter(NEXT_ID %in% WithIt$NEXT_ID )

```



##4. Prediciton of infantis using infant's information
```{r,  warning=FALSE, message=FALSE}
Variables = c("NEXT_ID", "NG_ID", "Infantis_present", "Timepoint_categorical", "exact_age_days_at_collection" )
sp_df %>% select("NG_ID", Prevalent_infant)  %>% left_join(sp_infant %>% select(Variables  )  ) %>% drop_na() -> sp_df_model
sp_df_model %>% mutate(Infantis_present = ifelse(Infantis_present == 1 , T, F) ) -> sp_df_model
sp_df_model %>% group_by(NEXT_ID,Infantis_present) %>% summarise(N = n()) %>% filter(Infantis_present == T) ->EverInfantis


sp_df_model %>% mutate(Ever_Infantis = ifelse(NEXT_ID %in% EverInfantis$NEXT_ID, T, F) ) -> sp_df_model
sp_df_model %>% group_by(Ever_Infantis) %>% summarise(n())
sp_df_model %>% distinct(NEXT_ID, .keep_all=T) %>% group_by(Ever_Infantis) %>% summarise(n())
```

###4.1 Ever infantis?


```{r, warning=FALSE, message=FALSE}
# Predicitons Ever infantis presence?

coda_glmnet_longitudinal(x = sp_df_model %>% select(-c(Variables, "Bifidobacterium_longum.t__subsp.infantis", "Ever_Infantis" )) %>% as.matrix() , y=sp_df_model$Ever_Infantis, x_time=sp_df_model$exact_age_days_at_collection, subject_id =sp_df_model$NEXT_ID,  nfolds = 10, ini_time=3, end_time = 436 ) -> Model3
Model3$`mean cv-AUC`
Model3$`signature plot`



#Removing other longum subspecies, in case there are multimappers
coda_glmnet_longitudinal(x = sp_df_model %>% select(-c(Variables,Longum, "Ever_Infantis" )) %>% as.matrix() , y=sp_df_model$Ever_Infantis, x_time=sp_df_model$exact_age_days_at_collection, subject_id =sp_df_model$NEXT_ID,  nfolds = 10, ini_time=3, end_time = 436 ) -> Model4
Model4$`mean cv-AUC`
Model4$`signature plot`

```

###4.2 Infantis presence per timepoint?
```{r, warning=FALSE, message=FALSE}
AUCs_cross= tibble()
Variables = c(Variables, "Ever_Infantis")
Models = list()
Iter = 1
#sp_df_model %>% mutate( Infantis_present = ifelse(Infantis_present == T, 1, 0) ) -> sp_df_model
for (Timepoint in unique(sp_df_model$Timepoint_categorical) ) {
  print(Timepoint)
  coda_glmnet(x = sp_df_model %>% filter(Timepoint_categorical==Timepoint) %>% select(-c(Variables, "Bifidobacterium_longum.t__subsp.infantis")) %>% as.matrix() , y=sp_df_model %>% filter(Timepoint_categorical==Timepoint) %>% select(Infantis_present) %>%as_vector(), nfolds = 10 ) -> Model1
  AUC = Model1$`mean cv-AUC`
  SD = Model1$`sd cv-AUC`
  tibble(Timepoint = Timepoint,  AUC = AUC, SD = SD) %>% rbind(AUCs_cross, . ) -> AUCs_cross
  Models[[Iter]] = Model1
  Iter = Iter + 1
}  
AUCs_cross %>% mutate( Timepoint = factor(Timepoint, levels=Order_time))  %>% ggplot(aes(x=Timepoint, y=AUC)) + geom_point() + geom_errorbar(aes(ymin = AUC - SD, ymax = AUC + SD), width = 0.2) + theme_bw() + coord_flip()

#For model M6 / M9, check if predictions correlate with abundance
Model_check = Models[[3]] #4 for M6
sp_df_model %>% filter(Timepoint_categorical=="M9") %>% mutate(Pred = Model_check$predictions) -> Plotstuff
Plotstuff %>% ggplot(aes(x=as.factor(Infantis_present), y= Pred  )) + geom_boxplot(outlier.shape =  NA)  + ggforce::geom_sina(aes(col= AST_transform(`Bifidobacterium_longum.t__subsp.infantis`))) + theme_bw()
Plotstuff %>%  ggplot(aes(x=Pred, y=  AST_transform(`Bifidobacterium_longum.t__subsp.infantis`)))  + geom_point() + theme_bw()


```

####4.3 Community in one timepoint prediction of infantis presence in other moments
```{r, warning=FALSE, message=FALSE}

Run_Prediction_Time = function(BL){
  AUCs_cross2= tibble()
  Variables = c(Variables, "Ever_Infantis")
  Models = list()
  Iter = 1
  for (Timepoint in unique(sp_df_model$Timepoint_categorical) ) {
    if (Timepoint == BL){ next }
    print(Timepoint)
    #Get infants that are available in W2 and the other timepoint
    sp_df_model %>% filter(Timepoint_categorical %in% c(BL, Timepoint) ) %>% group_by(NEXT_ID) %>% summarise(N = n()) %>% filter(N > 1)  -> D
    InputM = sp_df_model %>% filter(NEXT_ID  %in% D$NEXT_ID )
    coda_glmnet(x = InputM  %>% filter(Timepoint_categorical==BL) %>% select(-c(Variables, "Bifidobacterium_longum.t__subsp.infantis")) %>% as.matrix() , y=InputM %>% filter(Timepoint_categorical==Timepoint) %>% select(Infantis_present) %>%as_vector(), nfolds = 5 ) -> Model1
    AUC = Model1$`mean cv-AUC`
    tibble(Timepoint = Timepoint,  AUC = AUC, SD = Model1$`sd cv-AUC` ) %>% mutate(Timepoint =Timepoint ) %>% rbind(AUCs_cross2, . ) -> AUCs_cross2
    Models[[Iter]] = Model1
    Iter = Iter + 1
  } 
  return(AUCs_cross2)
}
AUCs_cross_m = tibble()
for (i in unique(sp_df_model$Timepoint_categorical) ){
   print(paste0("Running: ", i) )
   AUCs_cross_m %>% rbind(Run_Prediction_Time(i) %>% mutate(Predicting_time = i) ) -> AUCs_cross_m
}
AUCs_cross_m %>% select(-SD) %>% spread(Predicting_time, AUC) %>% as.data.frame() %>% column_to_rownames("Timepoint") %>% as.matrix() -> ForPlot
ForPlot[Order_time[4:10],Order_time[4:10]] -> ForPlot
colnames(ForPlot) = sapply(colnames(ForPlot), function(x){ paste0(x, "_community") } )
rownames(ForPlot) = sapply(rownames(ForPlot), function(x){ paste0(x, "_infantis") } )
ForPlot %>%  corrplot::corrplot(method = 'number')  #pheatmap::pheatmap(cluster_rows = F, cluster_cols = F)



```



##5. Infantis prediction using mother's information
Here, it is important to consider that twins are taken as independent samples
These families can be checked with:
`metadat_temp %>% filter(Type == "infant") %>% group_by(FAMILY) %>% summarise(distinct_next_ids = n_distinct(NEXT_ID)) %>% filter(distinct_next_ids >= 2 )`

```{r, warning=FALSE, message=FALSE}
#Can we predict based on mother abundance?
AUCs_mother=tibble()
for (Timepoint in unique(sp_df_model$Timepoint_categorical) ) {
  print(Timepoint)
  
  metadata_long  %>% filter(Type == "mother" | (Type == "infant" & Timepoint_categorical == Timepoint ) ) -> metadat_temp
  metadat_temp %>% filter(Type == "infant") %>% select(FAMILY,NG_ID) %>% rename(Infant_id = NG_ID) %>% left_join(metadat_temp, .) %>% drop_na() -> metadat_temp
  metadat_temp %>% filter(Type == "mother") %>% left_join(sp_df_model %>% select(NG_ID, Infantis_present), by=c("Infant_id" = "NG_ID") ) %>% filter(!Timepoint_categorical %in% c("M1", "M2") ) %>%
    mutate(TimeNumeric = ifelse(Timepoint_categorical == "P12", -24, ifelse(Timepoint_categorical %in% c("P28", "B") , 0, 12  ) )  ) -> metadat_temp
  
  sp_df %>% select(NG_ID, Prevalent_mother) %>% left_join(metadat_temp, .) -> ForModel
  colnames(metadat_temp) -> RM
  ForModel %>% drop_na() -> ForModel
  
  #Samples with only one timepoint
  ForModel %>% group_by(NEXT_ID,TimeNumeric) %>% summarise(N = n()) %>% group_by(NEXT_ID) %>% summarise(N2 = n()) %>% filter(N2 == 1 ) -> OnlyOne
  ForModel %>% filter(! NEXT_ID %in% OnlyOne$NEXT_ID ) -> ForModel
  
  coda_glmnet_longitudinal(x = ForModel %>% select(-c(RM)) %>% as.matrix() , y=ForModel$Infantis_present, x_time=ForModel$TimeNumeric , subject_id =ForModel$NEXT_ID,  nfolds = 10, ini_time=-24, end_time = 12 ) -> Model_mother
  AUC = Model_mother$`mean cv-AUC`
  tibble(Timepoint = Timepoint,  AUC = AUC, SD=Model_mother$`sd cv-AUC` ) %>% rbind(AUCs_mother, . ) -> AUCs_mother
  Model_mother$`signature plot`

}

AUCs_mother %>% mutate( Timepoint = factor(Timepoint, levels=Order_time))  %>% ggplot(aes(x=Timepoint, y=AUC)) + geom_point() + geom_errorbar(aes(ymin = AUC - SD, ymax = AUC + SD), width = 0.2) +  theme_bw() + coord_flip()

```
###5.2 Mother prediction if infantis ever

```{r, warning=FALSE, message=FALSE}
#Can we predict based on mother abundance?

metadata_long  %>% filter(Type == "mother"  ) %>% left_join(sp_df_mother)  -> metadat_temp
sp_df_model %>% select(NG_ID, Ever_Infantis) %>% left_join(metadata_long %>% select(NG_ID, FAMILY ) ) %>% distinct(FAMILY, .keep_all=T) %>% select(-NG_ID) %>% left_join(metadat_temp,. , by="FAMILY" ) -> metadat_temp

metadat_temp  %>% filter(!Timepoint_categorical %in% c("M1", "M2") ) %>% mutate(TimeNumeric = ifelse(Timepoint_categorical == "P12", -24, ifelse(Timepoint_categorical %in% c("P28", "B") , 0, 12  ) )  ) -> metadat_temp
  
metadat_temp %>% drop_na() -> ForModel
#Samples with only one timepoint
ForModel %>% group_by(NEXT_ID,TimeNumeric) %>% summarise(N = n()) %>% group_by(NEXT_ID) %>% summarise(N2 = n()) %>% filter(N2 == 1 ) -> OnlyOne
ForModel %>% filter(! NEXT_ID %in% OnlyOne$NEXT_ID ) -> ForModel
  
coda_glmnet_longitudinal(x = ForModel %>% select(Prevalent_mother)  %>% as.matrix() , y=ForModel$Ever_Infantis, x_time=ForModel$TimeNumeric , subject_id =ForModel$NEXT_ID,  nfolds = 10, ini_time=-24, end_time = 12 ) -> Model_mother
AUC = Model_mother$`mean cv-AUC`
Model_mother$`signature plot`
```



##6. Infantis prevalence and abundance association with phenotypes
```{r, warning=FALSE, message=FALSE}
#Association with phenotypes

#Attach to DF of infant samples with infantis information
left_join(left_join(sp_df_model, metadata_long %>% select("NG_ID", "NEXT_ID") ),  metadatacross %>% rename(NEXT_ID =next_id_infant ) ) %>% left_join(dynamic) -> ForModel
#abundance of infantis should be CLR-transformed, l2 (infants-only)
CRL_taxa_l2 %>% select(NG_ID, `Bifidobacterium_longum.t__subsp.infantis` ) -> Toattach
ForModel %>% select(-`Bifidobacterium_longum.t__subsp.infantis`) %>% left_join(Toattach) -> ForModel
Associations_phenotypes= tibble()
for (Pheno in c(colnames(metadatacross), colnames(dynamic), "exact_age_days_at_collection" ) ){
  if (Pheno %in% c("next_id_infant", "NG_ID", "NEXT_ID", "SAMPLE_ID" ) ){ next }
  print(Pheno)
  ForModel %>% filter(!is.na(!!sym(Pheno))) -> ForModel2
  if (dim(ForModel2)[1] < 50){ next }
  Formula = paste0( "Ever_Infantis ~ ", Pheno )
  glm(Formula, ForModel %>% distinct(NEXT_ID, .keep_all=T) , family = binomial() ) %>% summary() -> Model1
  if (Pheno != "exact_age_days_at_collection"){
    Formula = paste0( "as.factor(Infantis_present) ~ scale(exact_age_days_at_collection)+ ", Pheno, " + (1|NEXT_ID)" )
  } else {
    Formula = paste0( "as.factor(Infantis_present) ~ scale(", Pheno, ") + (1|NEXT_ID)" )
  }
  glmer(Formula, ForModel, family = binomial() ) %>% summary() -> Model2
  if (Pheno != "exact_age_days_at_collection"){
    Formula = paste0( "`Bifidobacterium_longum.t__subsp.infantis` ~ scale(exact_age_days_at_collection)+", Pheno, " + (1|NEXT_ID)" )
  } else {
    Formula = paste0( "`Bifidobacterium_longum.t__subsp.infantis` ~ scale(", Pheno, ") + (1|NEXT_ID)" )
  }
  lmerTest::lmer(Formula, ForModel) %>% summary() -> Model3
  
  
  tail(as_tibble(Model1$coefficients),1) %>% mutate(Dependent="Ever_Infantis") %>% select(- `z value`) %>% rename(P=`Pr(>|z|)`) -> R1
  tail(as_tibble(Model2$coefficients),1) %>% mutate(Dependent="Infantis_present") %>% select(- `z value`) %>%rename(P=`Pr(>|z|)`)   -> R2
  tail(as_tibble(Model3$coefficients),1) %>% mutate(Dependent="Infantis_abundance") %>% select(- c(`t value`, df)) %>% rename(P=`Pr(>|t|)`)  -> R3
  
  if (Pheno %in% colnames(dynamic) ) { rbind(R2, R2) %>% mutate(Phenotype = Pheno) %>% rbind(Associations_phenotypes, . ) ->   Associations_phenotypes 
  } else {
  rbind(R1, R2) %>% rbind(R3) %>% mutate(Phenotype = Pheno) %>% rbind(Associations_phenotypes, . ) ->   Associations_phenotypes
  }
}
Associations_phenotypes %>% arrange(P) %>% mutate(FDR = p.adjust(P, "fdr")) %>% select(-`Std. Error`) %>% head(n=20) %>% gt::gt()

```

###6.2 Are there geographical reasons for the infantis/no infantis?
```{r }
library(geosphere)

read_csv("~/Documents/PhD/LL_NEXT/Mantel/Data/LLNEXT_geo_location_municipality.csv") -> Latitude_longitude_info
metadata_long %>% left_join(Latitude_longitude_info %>% rename(NEXT_ID=next_id_mother) ) %>% drop_na() %>% distinct(NEXT_ID, .keep_all=T) %>% select(-c(Timepoint_categorical,exact_age_days_at_collection, Type))  -> metadata_motherIDs
sp_infant %>% left_join(metadata_long) %>% select(-c(NG_ID, NEXT_ID)) -> infant_add
sp_infant %>% left_join(metadata_long) %>% group_by(NEXT_ID) %>% summarise(EverInfantis = as.numeric(any(Infantis_present == 1))) %>% left_join(sp_infant) %>% left_join(metadata_long) %>% distinct(NEXT_ID, .keep_all=T) %>% select( FAMILY,EverInfantis ) -> infant_add
left_join(metadata_motherIDs %>% distinct(NEXT_ID, .keep_all=T) , infant_add, by="FAMILY") %>% drop_na() %>% distinct(FAMILY, .keep_all=T) -> Infant_with_location
Infant_with_location %>% dplyr::select(lon, lat) %>% as.matrix()  %>% distm(. ,  fun = distVincentySphere) -> geographical_distance


adonis2( geographical_distance ~ Infant_with_location$EverInfantis )
rownames(geographical_distance) = Infant_with_location$FAMILY ; colnames(geographical_distance) = Infant_with_location$FAMILY

#library(MCMCglmm)
#library(MASS)
#prior1<-list(R=list(V=1,fix=1), G=list(G1=list(V=1,nu = 0.001) ) )
#M1 <- as(ginv(geographical_distance), "dgCMatrix")
#similarity_matrix <- exp(-geographical_distance)
#covariance_matrix <- cov(similarity_matrix)
#solve(covariance_matrix) -> M1
#M1@Dimnames <- list(Infant_with_location$FAMILY, Infant_with_location$FAMILY)
#MCMCglmm.object = MCMCglmm(EverInfantis ~ 1,
#                              random = ~FAMILY, 
#                              ginverse = list(FAMILY = M1),
#                              prior = prior1,
#                              data = as.data.frame(Infant_with_location),
#                              family = "threshold",nitt = 60000,burnin=20000, thin = 20) 
#plot(MCMCglmm.object)
#library(lme4qtl)
#relmatGlmer( as.factor(EverInfantis) ~ (1|FAMILY), Infant_with_location, relmat = list(FAMILY = geographical_distance), family = binomial("logit") ) -> m1
#lme4::VarCorr(m1)
#lme4qtl::VarProp(m1)


Infant_with_location %>% group_by(municipality) %>% summarise(Proportion_infantis = mean(EverInfantis), N= n() ) -> ProportionsInfant
ProportionsInfant %>% filter(N > 5 ) %>% ggplot(aes(x=municipality, y = Proportion_infantis)) + geom_bar(stat="identity") + theme_bw() + coord_flip() + geom_text(aes(label = paste("n =", N )),hjust=-0.5 ,size = 3)
ProportionsInfant %>% filter(N > 5 ) -> To_test
Infant_with_location %>% filter(municipality %in% To_test$municipality) -> To_test
glm(as.factor(EverInfantis)  ~ 1 , To_test, family=binomial()  ) -> D0
glm(as.factor(EverInfantis)  ~ municipality , To_test, family=binomial()  ) -> D1
anova(D1, D0, test = "Chisq")

```


##7. Check the prevalence of infantis in other adults

```{r, warning=FALSE, message=FALSE}
read_tsv("~/Documents/PhD/LL_NEXT/Transmission/metadata/LLD_MP4Moran.tsv", skip = 1) -> LLD_MP4
LLD_MP4$clade_name -> COLN  
LLD_MP4 %>% select(-clade_name) %>% t() %>% as_tibble() %>% mutate(NG_ID = colnames(LLD_MP4 %>% select(-clade_name) ), .before=1 ) -> LLD_MP4

colnames(LLD_MP4) = c("NG_ID", COLN)
Filter_names(LLD_MP4,Do_Genus = F) -> LLD_MP4
colnames(LLD_MP4) = colnames(LLD_MP4) %>% sapply(function(x){str_replace_all(x, "\\|", ".") } ) 

colnames(LLD_MP4)[grepl("longum", colnames(LLD_MP4))] -> Longum
LLD_MP4 %>% summarise(
    mean_infantis = mean(`Bifidobacterium_longum.t__subsp.infantis`, na.rm = TRUE),
    mean_infantis_if_present = mean(`Bifidobacterium_longum.t__subsp.infantis`[`Bifidobacterium_longum.t__subsp.infantis`> 0], na.rm = TRUE),
    count= n(),
    count_infantis =sum(`Bifidobacterium_longum.t__subsp.infantis`> 0, na.rm = TRUE) ,
    prevalence_infantis = mean(`Bifidobacterium_longum.t__subsp.infantis`> 0, na.rm = TRUE)
  )

LLD_MP4$NG_ID = str_replace(LLD_MP4$NG_ID, "_metaphlan", "")

Prevalence_LLD = LLD_MP4 %>% select(-NG_ID) %>% apply(2, function(x){ sum(x!=0)/length(x) } )
To_keep = c("NG_ID", "Bifidobacterium_longum.t__subsp.infantis", names(Prevalence_LLD[Prevalence_LLD>0.1]) )
LLD_MP4 %>% select(To_keep) %>% mutate(Presence_infantis = ifelse(`Bifidobacterium_longum.t__subsp.infantis`>0, 1, 0), .before=-2  ) %>%
  select(-`Bifidobacterium_longum.t__subsp.infantis`) -> LLD_MP4_filt
```
###7.1 Check which taxa are associated to the presence of infantis
```{r, warning=F, message=F}
Assoc_LLD = tibble()
LLD_MP4_filt %>% select(-c(Presence_infantis, NG_ID)) %>% decostand(., 'clr', pseudocount=my_pseudocount_normal) %>% mutate(Presence_infantis = LLD_MP4_filt$Presence_infantis, NG_ID= LLD_MP4_filt$NG_ID) -> LLD_MP4_filt_clr
for (Taxa in names(Prevalence_LLD)[Prevalence_LLD>0.2] ){
  if (Taxa == "Bifidobacterium_longum.t__subsp.infantis"){ next }
  Formula = paste0("as.factor(Presence_infantis) ~ `", Taxa, "`")
  glm(Formula, LLD_MP4_filt_clr, family=binomial("logit")) -> Res
  summary(Res)$coefficients %>% as_tibble() %>% tail(1) %>% mutate(Sp = Taxa, N_infantis=dim(filter(LLD_MP4_filt_clr, Presence_infantis==1))[1]) %>% rbind(Assoc_LLD, .) -> Assoc_LLD
  
}

Assoc_LLD %>% arrange(`Pr(>|z|)`) %>% mutate(FDR = p.adjust(`Pr(>|z|)`) ) %>% dplyr::select(-c(`Std. Error`, `z value`, N_infantis)) %>% filter(FDR < 0.05)

```
###7.2 Infantis prediction
Can the community predict the presence of infantis
```{r, warning=F, message=F}
To_keep = c("Presence_infantis", names(Prevalence_LLD[Prevalence_LLD>0.2]) )
LLD_MP4_filt %>% select(one_of(To_keep))  -> LLD_MP4_filt2
LLD_MP4_filt2 %>% mutate(Presence_infantis = ifelse(Presence_infantis==1, T, F) ) -> LLD_MP4_filt2
coda_glmnet(x = LLD_MP4_filt2 %>% select(-Presence_infantis)  %>% as.matrix() , y=LLD_MP4_filt2$Presence_infantis,  nfolds = 3 ) -> Model_pop

Model_pop$`mean cv-AUC`
```


###7.3 Phenotypes associaton
Merge with phenotypes and associate

```{r, warning=F, message=F}
read_delim("~/Documents/GitHub/CMV_Associations/Data/Merged_Phenotypes_LLD.csv", delim = "|") -> metadata_lld
Translate_IDs = read_tsv("~/Resilio Sync/Transfer/PhD/TMAO_project/rename_LLD.txt") %>% rename(NG_ID = ID, LLID=ID_1) -> Translated
metadata_lld %>% rename(LLID = ID ) %>% left_join(left_join(Translated, LLD_MP4_filt_clr)) -> metadata_lld_merged
Assoc_LLD2 = tibble()

for (D in colnames(metadata_lld)){
    if (D %in%  c("ID", "NG_ID")) { next }
  Formula = paste0("as.factor(Presence_infantis) ~ `", D, "`")
  metadata_lld_merged %>% select("Presence_infantis", D) %>% drop_na() -> InputModel
  InputModel %>% group_by(Presence_infantis) %>% summarise(n()) -> N_infantis
  if (dim(N_infantis)[1]< 2 ){ next }

  glm(Formula, InputModel, family=binomial("logit")) -> Res
    summary(Res)$coefficients %>% as_tibble() %>% tail(1) %>% mutate(Phenotype = D, N=dim(InputModel)[1], N_infantis=dim(filter(InputModel, Presence_infantis==1))[1]) %>% rbind(Assoc_LLD2, .) -> Assoc_LLD2
}


```
###7.3 Associaton diet
```{r, warning=F, message=F}
read_tsv("~/Resilio Sync/lld_plasma_GeneralMet_analysis/data/data_1019samples_LLD_baseline_5diet_scores_adj_age_sex_smk.txt") -> diet
diet %>% rename(LLID = LL ) %>% left_join(left_join(Translated, LLD_MP4_filt_clr)) -> lld_diet_merged
Assoc_LLD3 = tibble()
for (D in colnames(diet)){
    if (D %in%  c("LL", "NG_ID")) { next }
  Formula = paste0("as.factor(Presence_infantis) ~ `", D, "`")
  lld_diet_merged %>% dplyr::select("Presence_infantis", D) %>% drop_na() -> InputModel
  InputModel %>% group_by(Presence_infantis) %>% summarise(n()) -> N_infantis
  if (dim(N_infantis)[1]< 2 ){ next }

  glm(Formula, InputModel, family=binomial("logit")) -> Res
    summary(Res)$coefficients %>% as_tibble() %>% tail(1) %>% mutate(Phenotype = D, N=dim(InputModel)[1], N_infantis=dim(filter(InputModel, Presence_infantis==1))[1]) %>% rbind(Assoc_LLD3, .) -> Assoc_LLD3
}

```
###7.3 Associaton metabolites
```{r, warning=F, message=F}
read.table("~/Resilio Sync/lld_plasma_GeneralMet_analysis/data/data_1442samples_LLD_baseline_1183plasma_metabolites.txt", sep = "\t", header = T) %>% rownames_to_column("LLID") %>% as_tibble() -> metabolomics
metabolomics  %>% left_join(left_join(Translated, LLD_MP4_filt_clr)) -> lld_diet_merged
Assoc_LLD4 = tibble()
for (D in colnames(metabolomics)){
    if (D %in%  c("LLID", "NG_ID")) { next }
  Formula = paste0("as.factor(Presence_infantis) ~ `", D, "`")
  lld_diet_merged %>% dplyr::select("Presence_infantis", D) %>% drop_na() -> InputModel
  InputModel %>% group_by(Presence_infantis) %>% summarise(n()) -> N_infantis
  if (dim(N_infantis)[1]< 2 ){ next }

  glm(Formula, InputModel, family=binomial("logit")) -> Res
    summary(Res)$coefficients %>% as_tibble() %>% tail(1) %>% mutate(Phenotype = D, N=dim(InputModel)[1], N_infantis=dim(filter(InputModel, Presence_infantis==1))[1]) %>% rbind(Assoc_LLD4, .) -> Assoc_LLD4
}
Assoc_LLD4 %>% arrange( `Pr(>|z|)`) %>% mutate(FDR = p.adjust( `Pr(>|z|)`, "fdr")) -> Assoc_LLD4
read_tsv("~/Resilio Sync/lld_plasma_GeneralMet_analysis/data/key_lld_1183meta_annotation.txt") %>% filter( meta %in% head(Assoc_LLD4, 3)$Phenotype )
```





# Part 3: Replication models

##3.1 Replication using CS-baby
```{r, warning=FALSE, message=FALSE}
read_tsv("~/Documents/PhD/LL_NEXT/Transmission/metadata/CS_Baby_Biome_MP4_Moran_db_24_01_2024.txt", skip=1) -> MP_cs
read_tsv("~/Documents/PhD/LL_NEXT/Transmission/metadata/Metadata_EGA_CS_BABY_BIOME.txt") -> metadata_cs

MP_cs$clade_name -> COLN  
MP_cs %>% select(-clade_name) %>% t() %>% as_tibble() %>% mutate(NG_ID = colnames(MP_cs %>% select(-clade_name) ), .before=1 ) -> MP_cs
colnames(MP_cs) = c("NG_ID", COLN)
Filter_names(MP_cs,Do_Genus = F) -> MP_cs
colnames(MP_cs) %>% sapply(function(x){ str_replace(x, "\\|", "\\.") } ) -> colnames(MP_cs)

MP_cs$NG_ID = str_replace(MP_cs$NG_ID,"_kneaddata_paired_metaphlan", "")

metadata_cs %>% rename(NG_ID = alias) %>% select(NG_ID,CS_BABY_BIOME_ID, Timepoint_categorical, Timepoint_numeric) %>% mutate(Type = ifelse(Timepoint_categorical == "MOM", "mother", "infant") ) -> metadata_cs
TimeOrder = c("W01", "W02", "W03", "W04", "W05", "W06", "M06", "M12", "MOM")
TimeOrder2 = c(1, 2,3,4,5,6,26,52)
metadata_cs %>% mutate(Timepoint_categorical =factor(Timepoint_categorical, levels = TimeOrder) ) -> metadata_cs


```

###3.1.1 Infantis exploration

We will start by checking infantis in this cohort
```{r, warning=FALSE, message=FALSE}
Longum = colnames(MP_cs)[grepl("longum", colnames(MP_cs))]
metadata_cs %>% left_join(MP_cs %>% select(NG_ID, c(Longum) ) ) %>% mutate(Infantis_present = ifelse(`Bifidobacterium_longum.t__subsp.infantis` == 0 , 0, 1) ) -> metadata_cs

metadata_cs %>% group_by(Timepoint_categorical) %>% summarise(N = n(), Prev_infantis  = mean(Infantis_present) ) %>% ggplot(aes(x=Timepoint_categorical, y=Prev_infantis)) + geom_bar(stat="identity") + theme_bw() + geom_text(aes(label = paste("n =", N)), vjust = -0.5, size = 3)

#Add infantis ever
metadata_cs %>% group_by(CS_BABY_BIOME_ID,Infantis_present) %>% summarise(N = n()) %>% filter(Infantis_present == T) ->EverInfantis_CS
metadata_cs %>% mutate(Ever_infantis = ifelse(CS_BABY_BIOME_ID %in% EverInfantis_CS$CS_BABY_BIOME_ID, 1, 0) ) -> metadata_cs

#Check gains losses of infantis
Exlore_infantis_gainandloss(metadata_cs %>% filter(Timepoint_categorical!="MOM"), ID_column = "CS_BABY_BIOME_ID", Timpeoint_column = "Timepoint_numeric") -> GainLoss_cs
Plot_gain_loss(GainLoss_cs, TimeOrder2)

```

###3.1.2 Infantis prediciton

Is a model trained in mother at birth timepoint able to reproduce in CS?

```{r, warning=FALSE, message=FALSE}
Get_AUC_glm = function(Model, Real){
  predicted_probabilities <- predict(Model, type = "response")
  auc <- roc(Real, predicted_probabilities)$auc
  return(auc)
}


#Using the model from previous section

metadata_cs %>% filter(Type=="mother") %>% select(NG_ID) %>% left_join(MP_cs) -> Mother_CS
Mother_CS %>% select(Model_mother$taxa.name) %>% impute_zeros() %>% apply(2, function( x ){ log10(x)  }  ) %*% Model_mother$`log-contrast coefficients` -> Ratio_scores

metadata_cs %>% filter(Type=="mother") %>% select(-Ever_infantis) %>% left_join(metadata_cs %>% filter(Type=="infant") %>% distinct(CS_BABY_BIOME_ID, .keep_all=T) %>% select(CS_BABY_BIOME_ID, Ever_infantis)   ) %>% mutate(Ratio = Ratio_scores) -> MotherInfo

MotherInfo %>% glm( as.factor(Ever_infantis) ~ Ratio, . , family = binomial() ) -> Model
Get_AUC_glm(Model, MotherInfo$Ever_infantis)
#Check the confusion matrix
predicted_classes <- ifelse(predict(Model, type = "response") > 0.5, 1, 0)
conf_matrix <- caret::confusionMatrix(factor(predicted_classes), factor(MotherInfo$Ever_infantis))




```

```{r, warning=FALSE, message=FALSE}
#Writing a model that is more similar
coda_glmnet(x = ForModel %>% filter(Timepoint_categorical == "B" ) %>% select(Prevalent_mother)  %>% as.matrix() , y=filter(ForModel, Timepoint_categorical == "B")$Ever_Infantis,  nfolds = 10 ) -> Model_mother2

metadata_cs %>% filter(Type=="mother") %>% select(NG_ID) %>% left_join(MP_cs) -> Mother_CS
Mother_CS %>% select(Model_mother2$taxa.name) %>% impute_zeros() %>% apply(2, function( x ){ log10(x)  }  ) %*% Model_mother2$`log-contrast coefficients` -> Ratio_scores

metadata_cs %>% filter(Type=="mother") %>% select(-Ever_infantis) %>% left_join(metadata_cs %>% filter(Type=="infant") %>% distinct(CS_BABY_BIOME_ID, .keep_all=T) %>% select(CS_BABY_BIOME_ID, Ever_infantis)   ) %>% mutate(Ratio2 = Ratio_scores) -> MotherInfo

MotherInfo %>% glm( as.factor(Ever_infantis) ~ Ratio2, . , family = binomial() ) -> Model2
Get_AUC_glm(Model2, MotherInfo$Ever_infantis)
#Check the confusion matrix
predicted_classes <- ifelse(predict(Model2, type = "response") > 0.5, 1, 0)
conf_matrix <- caret::confusionMatrix(factor(predicted_classes), factor(MotherInfo$Ever_infantis))

```





###3.2 Clustering in CS-baby
It requires to run first the clustering in LL-NEXT
####3.2.1 Preparation
```{r, warning=FALSE, message=FALSE}
#Keep only week 2 to make it simialr to LLNEXT
metadata_cs %>% filter(Timepoint_categorical == "W02") -> CS_InfoEarly
#LLNEXT taxa in early timepoint (W2)
#Early_filt
CS_InfoEarly %>% left_join(MP_cs) %>% drop_na() %>%  select(colnames(Early_filt)) -> CS_Earlyfilt

####Visualization
rbind(Early_filt, CS_Earlyfilt) %>% vegdist("bray") -> Dist_m
Label_cohort =  c( rep("LLNEXT", dim(Early_filt)[1]), rep("CS-baby", dim(CS_Earlyfilt)[1] ) )
PcoA_m=cmdscale(Dist_m, k = 20, eig = T)
PcoA_m$points %>% as_tibble() %>% mutate(Cohort =Label_cohort )   %>% as_tibble() %>% dplyr::rename(PC1 = V1, PC2 = V2, PC3 =V3, PC4=V4, PC5 = V5)  -> PC_early_2
Percn_var_2 = round(100*(PcoA_m$eig/sum(PcoA_m$eig)), 2)

PC_early_2 %>% ggplot(aes(x=PC1, y=PC2, col=Label_cohort)) + geom_point() + theme_bw()
PC_early_2 %>% ggplot(aes(x=PC1, y=PC4, col=Label_cohort)) + geom_point() + theme_bw()
```

####3.2.2 Training and clustering
```{r, warning=FALSE, message=FALSE}

##############
#Clustering###
##############

#We will use K-neirest neighbors on the lables of the clsuters from Early_filt. The distance used need to be set to Bray, and not Euclidean

Train = Early_filt
Labels_train = as.vector(as_vector(InfoEarly[C]))


KNN_distance = function(train, test, labels, metric = "bray", k =5 ){
  Distance = vegdist( rbind(train,test), metric )
  Train_indexes = seq(1:dim(train)[1])

  nearest_clusters <- apply( as.matrix(Distance), 1, function(x, index) {
    #Remove itself: Not necessary for test
    #x = x[-index]
    #Just keep the ones with clusters
    DistanceToTrain = x[ Train_indexes ]
    #Get order of distance
    min_indices <- order(DistanceToTrain)
    #Labels in those indeces
    Labels_ordered = labels[min_indices]
    #Get the K closest  
    NearestClusters = Labels_ordered[1:k]
    #Choose the label:
    table(NearestClusters)  -> Choice
    tibble(Count = Choice, Cluster = names(Choice)) %>% filter(Count == max(Choice) ) -> Choice
    if (dim(Choice)[1] > 1 ){ return(NA) 
    } else { return(Choice$Cluster ) }
  })
  tibble(Index =  names(nearest_clusters), Cluster = as.vector(nearest_clusters)) %>% filter(!Index %in%  Train_indexes) %>%
  return()
}

#We will optimize the k number
#For that we will split Train in train/test and check how well KNN does at different k
Train_index = sample( seq(1:dim(Train)[1]), dim(Train)[1]*0.5, replace=F)
Train[Train_index,] -> Train_1
Train[-Train_index,] -> Train_2
Result_knn_train = tibble()
for (i in 1:10 ){
  Result = KNN_distance(Train_1, Train_2, Labels_train[Train_index], k = i , metric = "bray" )
  Result %>% mutate(Real = Labels_train[-Train_index] ) -> Result
  Result %>% group_by(Cluster, Real) %>% summarise(N = n()) -> Summary_r
  Summary_r %>% filter(Cluster == Real) -> N1
  Accuracy = sum(N1$N)/sum(Summary_r$N)   
  Result_knn_train %>% rbind( tibble(K = i,  Accuracy = Accuracy)) -> Result_knn_train
}
Result_knn_train %>% arrange(desc(Accuracy)) -> R

##Predict in the CS dataset using the optimal number of neigbors

predicted_classes <- KNN_distance(train = Train, test = CS_Earlyfilt, labels = Labels_train, k = R[1,]$K , metric = "bray" )
CS_InfoEarly[C] = predicted_classes$Cluster

```

####3.2.3 Plotting clusters
```{r, warning=FALSE, message=FALSE}
CS_Earlyfilt %>% mutate(NG_ID = CS_InfoEarly$NG_ID ) %>% as.data.frame() %>% column_to_rownames("NG_ID") %>% pheatmap::pheatmap(annotation_row = CS_InfoEarly %>% select(c("NG_ID",C) ) %>% as.data.frame() %>% column_to_rownames("NG_ID"))

PC_early_2[C] = c(as_vector(InfoEarly[C]), as_vector(CS_InfoEarly[C]) )  


Plot_function(PC_early_2, Show_cluster = T, Bacteria = NA, X="PC1", Y="PC2", Cluster = C, Shape = "Cohort", Percn_var =Percn_var_2  )
Plot_function(PC_early_2, Show_cluster = T, Bacteria = NA, X="PC1", Y="PC3", Cluster = C, Shape = "Cohort", Percn_var =Percn_var_2  )
Plot_function(PC_early_2, Show_cluster = T, Bacteria = NA, X="PC1", Y="PC4", Cluster = C, Shape = "Cohort", Percn_var =Percn_var_2  )

```

###3.2 Predicting clusters in CS-baby using models trained in LL-NEXT

Getting labels for the analysis
```{r, warning=FALSE, message=FALSE}
metadata_cs %>% left_join(CS_InfoEarly %>% select("CS_BABY_BIOME_ID", C) ) -> metadata_cs
```
####3.3 Predicting based on late timepoints
Training LLNEXT on timepoints M06 and M12
```{r, warning=FALSE, message=FALSE }
#######################################
#Previous model
Scores %>% arrange(desc(CVAUC)) %>% head(1) -> N 
Previously_trainedModel =Models[[N$Cluster]]

metadata_cs %>% filter(Timepoint_categorical %in% c("M06", "M12")) -> TimepointToCheck
TimepointToCheck %>% mutate(Cluster = ifelse( !!sym(C) == N$Cluster, T, F  )  ) -> TimepointToCheck
left_join(TimepointToCheck, MP_cs) -> ForAnalysis_CS_late


ForAnalysis_CS_late %>% select(Previously_trainedModel$taxa.name) %>% impute_zeros() %>% apply(2, function( x ){ log10(x)  }  ) %*% Previously_trainedModel$`log-contrast coefficients` -> Ratio_scores_CSlate
TimepointToCheck %>% mutate(Ratio = as.vector(Ratio_scores_CSlate)) -> TimepointToCheck
TimepointToCheck %>% ggplot(aes(x=Timepoint_numeric, y=Ratio, col=Cluster )) + geom_point() + theme_bw() + geom_smooth(method = "lm")

TimepointToCheck %>% glm( Cluster ~ Ratio, . , family = binomial() ) -> Model
Get_AUC_glm(Model2, TimepointToCheck$Cluster)



#######################################
#Train new model in available datasets
metadata_long %>% filter(Timepoint_categorical %in% c("M6", "M12") ) -> Late
df2_3 %>% filter(NG_ID %in% Late$NG_ID ) %>% Filter_names(Do_Genus = F) -> sp_df_late
Late %>% left_join(PC_early %>% select(NEXT_ID, !!sym(C)) ) %>% drop_na() -> Late_with_info
sp_df_late %>% select(-NG_ID) %>% apply(2, function(x){ sum(x!=0)/length(x) } ) -> Prev_analysis
names(Prev_analysis)[Prev_analysis>0.2] -> Prev_analysis
ForAnalysis = left_join(Late_with_info,sp_df_late)
ForAnalysis %>% mutate(Cluster = ifelse( !!sym(C) == N$Cluster , T, F), .before=1 ) %>% filter(Timepoint_categorical %in% Late$Timepoint_categorical) %>% drop_na() -> ForAnalysis2
coda_glmnet_longitudinal(x = ForAnalysis2 %>% dplyr::select(Prev_analysis)  %>% as.matrix()  , y=ForAnalysis2$Cluster, x_time=ForAnalysis2$exact_age_days_at_collection, subject_id =ForAnalysis2$NEXT_ID,  nfolds = 5, ini_time=178, end_time = 396 ) -> Model_cluster
  

```






